{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03 NLP Facts about a Topic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/COG_GN22CDBDS001_MARCH_22/blob/main/NLP_Facts_about_a_Topic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7d3pZhShlEa",
        "outputId": "51ed0020-4644-4a05-aa29-992b280212ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TEXTACY -> Adds a lot of functionality that we use in NLP\n",
        "# day to day\n",
        "!pip install textacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "# NLP popular libraries-> Textacy, Spacy, NLTK "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textacy\n",
            "  Using cached textacy-0.11.0-py3-none-any.whl (200 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.21.5)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.23.0)\n",
            "Collecting cytoolz>=0.10.1\n",
            "  Using cached cytoolz-0.11.2.tar.gz (481 kB)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.1.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (2.6.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (1.4.1)\n",
            "Collecting spacy>=3.0.0\n",
            "  Using cached spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.2.4)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.7/dist-packages (from textacy) (4.63.0)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Using cached pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Using cached jellyfish-0.9.0.tar.gz (132 kB)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz>=0.10.1->textacy) (0.11.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->textacy) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (7.1.2)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (1.0.6)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.0.6)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (3.10.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (0.9.0)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->textacy) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: cytoolz, jellyfish\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1230864 sha256=48cc106ef4331173edee0c05a90ba059bbb8a5a30d634a9102bd98ee7e027803\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73969 sha256=0d084e8b3ebcb9f3507f18c0faa6453f8bda9711adb36d81ec5ee4437b45a942\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built cytoolz jellyfish\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, pyphen, jellyfish, cytoolz, textacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.7 cytoolz-0.11.2 jellyfish-0.9.0 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 pyphen-0.12.0 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.2 textacy-0.11.0 thinc-8.0.15 typer-0.4.1\n",
            "Collecting en-core-web-lg==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
            "\u001b[K     |█████████████████████           | 507.9 MB 1.4 MB/s eta 0:03:20"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1s9-YGMiNe2",
        "outputId": "921d48cc-5e08-4abd-8eb7-162ced9b8757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "import textacy\n",
        "dictionary = spacy.load('en_core_web_lg')\n",
        "f = open('text.txt','rt')\n",
        "data = f.read()\n",
        "doc = dictionary(data)\n",
        "len(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4053"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOXV3T1hi0tD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9626ea9-0ee4-4e62-baf2-85152845563f"
      },
      "source": [
        "statements = textacy.extract.semistructured_statements(doc,entity=\"shrimp\", cue='be')\n",
        "# be-> is, be, am, was.. \n",
        "# have-> has, have, had.. \n",
        "\n",
        "# a LIST of (subject, verb, fact)\n",
        "# SUBJECT -> search term \n",
        "print('This is all we know about Mantis Shrimp!')\n",
        "for statement in statements:\n",
        "  subject, verb, fact = statement \n",
        "  print(f\"-  {fact}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is all we know about Mantis Shrimp!\n",
            "-  [carnivorous, marine, crustaceans, of, the, order, Stomatopoda]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Efqa-5M_l6pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB6DrRiZlVbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50744c1d-de15-4a41-f190-f3491b597713"
      },
      "source": [
        "# COMPLEX words which forn NOUN \n",
        "chunkOfNouns = textacy.extract.noun_chunks(doc, min_freq=3) # no. of times noun chunks occur in dataset\n",
        "# THIS IS A LIST OF TOKENS, so we need to convert into string \n",
        "# before using/printing \n",
        "allnounchunks = []\n",
        "chunkOfNouns = map(str, chunkOfNouns)  # TYPE CASTING! str(chunkOfNoun[:])\n",
        "chunkOfNouns = map(str.lower, chunkOfNouns)\n",
        "for chunk in chunkOfNouns:\n",
        "  if len(chunk.split(' ')) > 1: # how long should a noun chunk be\n",
        "    #print(chunk)\n",
        "    allnounchunks.append(chunk)\n",
        "uniquenounchunks = set(allnounchunks)\n",
        "uniquenounchunks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'colour filters',\n",
              " 'deep ultraviolet',\n",
              " 'mantis shrimp',\n",
              " 'mantis shrimps',\n",
              " 'other species',\n",
              " 'photoreceptor cells',\n",
              " 'polarised light',\n",
              " 'spectral tuning',\n",
              " 'their prey',\n",
              " 'upper and lower hemispheres'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acr = textacy.extract.acronyms(doc)\n",
        "for ac in acr:\n",
        "  print(ac)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDXiueGov2ki",
        "outputId": "16ffd518-6b9e-47ff-8195-a680d0cd9250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UVB\n",
            "UV\n",
            "UV\n",
            "SE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHSbqsmTr5LB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08bc8a78-da79-4a20-b0a7-0f54d6093aaa"
      },
      "source": [
        "dir(textacy.extract)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " 'acronyms',\n",
              " 'acronyms_and_definitions',\n",
              " 'acros',\n",
              " 'aggregate_term_variants',\n",
              " 'basics',\n",
              " 'clean_term_strings',\n",
              " 'direct_quotations',\n",
              " 'entities',\n",
              " 'extensions',\n",
              " 'get_doc_extensions',\n",
              " 'keyterms',\n",
              " 'keyword_in_context',\n",
              " 'kwic',\n",
              " 'matches',\n",
              " 'ngrams',\n",
              " 'noun_chunks',\n",
              " 'regex_matches',\n",
              " 'remove_doc_extensions',\n",
              " 'semistructured_statements',\n",
              " 'set_doc_extensions',\n",
              " 'subject_verb_object_triples',\n",
              " 'terms',\n",
              " 'terms_to_strings',\n",
              " 'token_matches',\n",
              " 'triples',\n",
              " 'utils',\n",
              " 'words']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ko31baygvpEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}